{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_min_knowns(n):\n",
    "\n",
    "    rank = 2\n",
    "\n",
    "    U = np.random.randn(n, rank)\n",
    "    V = np.random.randn(n, rank)\n",
    "    original = np.dot(U, V.T)\n",
    "\n",
    "    for knowns in range(1, n*n):\n",
    "        threshold = 100\n",
    "\n",
    "        unknowns = n*n - knowns\n",
    "\n",
    "        mask = np.array([0] * unknowns + [1] * (n*n - unknowns))\n",
    "        mask = np.ma.make_mask(mask)\n",
    "\n",
    "        np.random.shuffle(mask)\n",
    "        mask = np.reshape(mask, [n,n])\n",
    "\n",
    "        def line_search(point, grad, obj_func, s = 4, threshold = 1e-10):\n",
    "            \"\"\" Finds a maximum step size that maximizes the descent (since computing gradient is hard) \"\"\"\n",
    "\n",
    "            choice = point - grad * s\n",
    "            while obj_func(choice) > obj_func(point):\n",
    "                s = s / 2\n",
    "                choice = point - grad * s\n",
    "\n",
    "            initial_s = s\n",
    "\n",
    "            while True:\n",
    "                left = choice + grad * s/2\n",
    "                right = point - grad * s/2\n",
    "\n",
    "                s = s / 2\n",
    "                if obj_func(left) < obj_func(right):\n",
    "                    choice = left\n",
    "                else:\n",
    "                    choice = right\n",
    "\n",
    "                if np.abs(obj_func(left) - obj_func(right)) < threshold:\n",
    "                    break\n",
    "\n",
    "            return (choice, initial_s, s)\n",
    "\n",
    "        def obj_func(m):\n",
    "            svd = np.linalg.svd(m, compute_uv=False)\n",
    "\n",
    "            return np.sum(svd[2:]) \n",
    "\n",
    "        def comp_grad(m, boolMask, portion):\n",
    "            \"\"\" Computes gradient that maximizes the objective function \"\"\"\n",
    "            epsilon = 1e-3\n",
    "\n",
    "            grad = np.zeros([n,n])\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if boolMask[i,j] and np.random.random() > 1 - portion:\n",
    "                        diff = np.zeros([n,n])\n",
    "                        diff[i,j] = epsilon\n",
    "                        grad[i,j] = (obj_func(m + diff) - obj_func(m - diff))/(2*epsilon)\n",
    "\n",
    "            return grad\n",
    "\n",
    "        starting_point = np.copy(original)\n",
    "\n",
    "        boolMask = np.ma.make_mask(np.where(np.array(mask) < 0.5, 1, 0))\n",
    "        starting_point[boolMask] = 0\n",
    "\n",
    "        prev_norm = np.linalg.norm(starting_point,'nuc')\n",
    "\n",
    "        norms = []\n",
    "        distances = []\n",
    "        sing_vals = []\n",
    "\n",
    "        current_point = starting_point\n",
    "\n",
    "        initial_s = 4\n",
    "        s = 4\n",
    "        portion = 1.1\n",
    "        for i in range(threshold):\n",
    "            cur_norm = np.linalg.norm(current_point,'nuc')\n",
    "            norms.append(cur_norm)\n",
    "            sing_vals.append(np.linalg.svd(current_point, compute_uv=False))\n",
    "            distances.append(np.linalg.norm(current_point-original,'fro'))\n",
    "            diff = cur_norm - prev_norm\n",
    "\n",
    "            #print(i, cur_norm, diff, np.linalg.norm(current_point-original,'fro'))\n",
    "            prev_norm = cur_norm\n",
    "            if diff >= 0 and i > 1:\n",
    "                break\n",
    "\n",
    "            ### slowest part of the code ###\n",
    "            grad = comp_grad(current_point,boolMask, portion)\n",
    "            current_point, initial_s, s = line_search(current_point, grad, obj_func, s = initial_s)\n",
    "\n",
    "        if i == threshold - 1:\n",
    "            return knowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_min_knowns(n):\n",
    "\n",
    "    rank = 2\n",
    "\n",
    "    U = np.random.randn(n, rank)\n",
    "    V = np.random.randn(n, rank)\n",
    "    original = np.dot(U, V.T)\n",
    "\n",
    "    for knowns in range(1, n*n):\n",
    "        max_steps = 100000\n",
    "        threshold = 1 # distance between solution and answer when they are considered the same\n",
    "\n",
    "        unknowns = n*n - knowns\n",
    "\n",
    "        mask = np.array([0] * unknowns + [1] * (n*n - unknowns))\n",
    "        mask = np.ma.make_mask(mask)\n",
    "\n",
    "        np.random.shuffle(mask)\n",
    "        mask = np.reshape(mask, [n,n])\n",
    "\n",
    "        \n",
    "        # First try Newton's method:\n",
    "\n",
    "        def comp_grad(m, boolMask, obj_func):\n",
    "            \"\"\" Computes gradient that maximizes the objective function \"\"\"\n",
    "            epsilon = 1e-3\n",
    "\n",
    "            # Yes, grad is a vector now\n",
    "            grad = []\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if boolMask[i,j] and np.random.random() > 1 - portion:\n",
    "                        diff = np.zeros([n,n])\n",
    "                        diff[i,j] = epsilon\n",
    "                        grad.append((obj_func(m + diff) - obj_func(m - diff))/(2*epsilon))\n",
    "\n",
    "            return grad\n",
    "\n",
    "        def comp_hessian(m, boolMask, of):\n",
    "            \"\"\" Computes hessian (only diagonal) \"\"\"\n",
    "            epsilon = 1e-3\n",
    "\n",
    "            hessian = []\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if boolMask[i,j]:\n",
    "                        row = []\n",
    "\n",
    "                        diff = np.zeros([n,n])\n",
    "                        diff[i,j] = epsilon\n",
    "                        hessian.append((of(m + diff) + of(m - diff) - 2*of(m))/epsilon**2)\n",
    "\n",
    "            return hessian\n",
    "\n",
    "\n",
    "        starting_point = np.copy(original)\n",
    "\n",
    "        boolMask = np.ma.make_mask(np.where(np.array(mask) < 0.5, 1, 0))\n",
    "        starting_point[boolMask] = 0\n",
    "\n",
    "        prev_norm = np.linalg.norm(starting_point,'nuc')\n",
    "\n",
    "        norms = []\n",
    "        distances = []\n",
    "        sing_vals = []\n",
    "\n",
    "        current_point = starting_point\n",
    "\n",
    "        #pl.imshow(np.abs((current_point-original)/original), cmap=plt.get_cmap('hot'),\n",
    "        #          interpolation='nearest', vmin=0, vmax=1)\n",
    "        #pl.colorbar()\n",
    "\n",
    "\n",
    "        initial_s = 4\n",
    "        s = 4\n",
    "        portion = 1.1\n",
    "        for i in range(max_steps):\n",
    "            cur_norm = np.linalg.norm(current_point,'nuc')\n",
    "            norms.append(cur_norm)\n",
    "            sing_vals.append(np.linalg.svd(current_point, compute_uv=False))\n",
    "            distances.append(np.linalg.norm(current_point-original,'fro'))\n",
    "            diff = cur_norm - prev_norm\n",
    "\n",
    "            # portion really should depend on s since smaller s implies the need of a more accurate gradient estimate\n",
    "            #portion = 1 - np.exp(-1/(20*s))\n",
    "            #if i % 1000 == 0:\n",
    "            #print(i, cur_norm, diff, np.linalg.norm(current_point-original,'fro'), initial_s, s, portion)\n",
    "            prev_norm = cur_norm\n",
    "            \n",
    "            if np.linalg.norm(current_point-original,'fro') < threshold:\n",
    "                return knowns\n",
    "            \n",
    "            if diff >= 0 and i > 1:\n",
    "                break\n",
    "\n",
    "            ### slowest part of the code ###\n",
    "            descent = np.linalg.lstsq(np.diag(comp_hessian(current_point,boolMask,obj_func)),\n",
    "               comp_grad(current_point,boolMask,obj_func), rcond=None)[0]\n",
    "\n",
    "            descent_matrix = np.zeros([n,n])\n",
    "            count = 0\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if boolMask[i,j]:\n",
    "                        descent_matrix[i,j] = descent[count]\n",
    "                        count = count + 1\n",
    "\n",
    "            reg = 0.39\n",
    "            next_point = current_point - reg*descent_matrix\n",
    "\n",
    "            current_point = next_point\n",
    "\n",
    "        # Next try gradient descent:\n",
    "        \n",
    "        def comp_grad(m,boolMask):\n",
    "            \"\"\" Computes gradient that maximizes the objective function \"\"\"\n",
    "            epsilon = 1e-3\n",
    "\n",
    "            grad = np.zeros([n,n])\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if boolMask[i,j]:\n",
    "                        diff = np.zeros([n,n])\n",
    "                        diff[i,j] = epsilon\n",
    "                        grad[i,j] = (obj_func(m + diff) - obj_func(m - diff))/(2*epsilon)\n",
    "\n",
    "            return grad\n",
    "        \n",
    "        def line_search(point, grad, obj_func, s = 4, threshold = 1e-10):\n",
    "            \"\"\" Finds a maximum step size that maximizes the descent (since computing gradient is hard) \"\"\"\n",
    "\n",
    "            choice = point - grad * s\n",
    "            while obj_func(choice) > obj_func(point):\n",
    "                s = s / 2\n",
    "                choice = point - grad * s\n",
    "\n",
    "            initial_s = s\n",
    "\n",
    "            while True:\n",
    "                left = choice + grad * s/2\n",
    "                right = point - grad * s/2\n",
    "\n",
    "                s = s / 2\n",
    "                if obj_func(left) < obj_func(right):\n",
    "                    choice = left\n",
    "                else:\n",
    "                    choice = right\n",
    "\n",
    "                if np.abs(obj_func(left) - obj_func(right)) < threshold:\n",
    "                    break\n",
    "\n",
    "            return (choice, initial_s, s)\n",
    "\n",
    "        starting_point = np.copy(original)\n",
    "\n",
    "        boolMask = np.ma.make_mask(np.where(np.array(mask) < 0.5, 1, 0))\n",
    "        starting_point[boolMask] = 0\n",
    "\n",
    "        prev_norm = np.linalg.norm(starting_point,'nuc')\n",
    "\n",
    "        norms = []\n",
    "        distances = []\n",
    "        sing_vals = []\n",
    "\n",
    "        current_point = starting_point\n",
    "\n",
    "        initial_s = 4\n",
    "        s = 4\n",
    "        portion = 1.1\n",
    "        for i in range(threshold):\n",
    "            cur_norm = np.linalg.norm(current_point,'nuc')\n",
    "            norms.append(cur_norm)\n",
    "            sing_vals.append(np.linalg.svd(current_point, compute_uv=False))\n",
    "            distances.append(np.linalg.norm(current_point-original,'fro'))\n",
    "            diff = cur_norm - prev_norm\n",
    "\n",
    "            #print(i, cur_norm, diff, np.linalg.norm(current_point-original,'fro'))\n",
    "            prev_norm = cur_norm\n",
    "            \n",
    "            if np.linalg.norm(current_point-original,'fro') < threshold:\n",
    "                return knowns\n",
    "            \n",
    "            if diff >= 0 and i > 1:\n",
    "                break\n",
    "\n",
    "            ### slowest part of the code ###\n",
    "            grad = comp_grad(current_point,boolMask)\n",
    "            current_point, initial_s, s = line_search(current_point, grad, obj_func, s = initial_s)\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_min_knowns(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 14\n",
      "6 35\n",
      "7 47\n",
      "8 62\n",
      "9 79\n",
      "10 78\n",
      "11 84\n",
      "12 104\n",
      "13 113\n",
      "14 142\n",
      "15 154\n",
      "16 185\n",
      "17 193\n",
      "18 225\n",
      "19 230\n",
      "20 265\n",
      "21 268\n",
      "22 266\n",
      "23 336\n",
      "24 320\n",
      "25 334\n",
      "26 344\n",
      "27 381\n",
      "28 404\n",
      "29 408\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-b3402e5f7c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmin_knowns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_min_knowns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin_knowns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mn_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-f9ab5c4cb607>\u001b[0m in \u001b[0;36mget_min_knowns\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;31m### slowest part of the code ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             descent = np.linalg.lstsq(np.diag(comp_hessian(current_point,boolMask,obj_func)),\n\u001b[0m\u001b[1;32m    101\u001b[0m                comp_grad(current_point,boolMask,obj_func), rcond=None)[0]\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-f9ab5c4cb607>\u001b[0m in \u001b[0;36mcomp_hessian\u001b[0;34m(m, boolMask, of)\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                         \u001b[0mdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                         \u001b[0mhessian\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhessian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcell_name\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(m)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->d'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1574\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1575\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_vals = []\n",
    "min_knowns_vals = []\n",
    "\n",
    "for n in range(4,10000):\n",
    "    min_knowns = get_min_knowns(n)\n",
    "    if min_knowns:\n",
    "        n_vals.append(n)\n",
    "        min_knowns_vals.append(min_knowns)\n",
    "        print(n, min_knowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa3af900780>]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_vals, min_knowns_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('convergence_n_vals', n_vals)\n",
    "np.save('convergence_min_known_vals', min_knowns_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
