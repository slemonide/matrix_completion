{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def obj_func(m):\n",
    "    svd = np.linalg.svd(m, compute_uv=False)\n",
    "\n",
    "    return np.sum(svd) \n",
    "\n",
    "def get_min_knowns(n):\n",
    "\n",
    "    rank = 2\n",
    "\n",
    "    U = np.random.randn(n, rank)\n",
    "    V = np.random.randn(n, rank)\n",
    "    original = np.dot(U, V.T)\n",
    "\n",
    "    for knowns in range(1, n*n):\n",
    "        max_steps = 100000\n",
    "        threshold = 1 # distance between solution and answer when they are considered the same\n",
    "\n",
    "        unknowns = n*n - knowns\n",
    "\n",
    "        mask = np.array([0] * unknowns + [1] * (n*n - unknowns))\n",
    "        mask = np.ma.make_mask(mask)\n",
    "\n",
    "        np.random.shuffle(mask)\n",
    "        mask = np.reshape(mask, [n,n])\n",
    "\n",
    "        \n",
    "        # First try Newton's method:\n",
    "\n",
    "        def comp_grad(m, boolMask, obj_func):\n",
    "            \"\"\" Computes gradient that maximizes the objective function \"\"\"\n",
    "            epsilon = 1e-3\n",
    "\n",
    "            # Yes, grad is a vector now\n",
    "            grad = []\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if boolMask[i,j] and np.random.random() > 1 - portion:\n",
    "                        diff = np.zeros([n,n])\n",
    "                        diff[i,j] = epsilon\n",
    "                        grad.append((obj_func(m + diff) - obj_func(m - diff))/(2*epsilon))\n",
    "\n",
    "            return grad\n",
    "\n",
    "        def comp_hessian(m, boolMask, of):\n",
    "            \"\"\" Computes hessian (only diagonal) \"\"\"\n",
    "            epsilon = 1e-3\n",
    "\n",
    "            hessian = []\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if boolMask[i,j]:\n",
    "                        row = []\n",
    "\n",
    "                        diff = np.zeros([n,n])\n",
    "                        diff[i,j] = epsilon\n",
    "                        hessian.append((of(m + diff) + of(m - diff) - 2*of(m))/epsilon**2)\n",
    "\n",
    "            return hessian\n",
    "\n",
    "\n",
    "        starting_point = np.copy(original)\n",
    "\n",
    "        boolMask = np.ma.make_mask(np.where(np.array(mask) < 0.5, 1, 0))\n",
    "        starting_point[boolMask] = 0\n",
    "\n",
    "        prev_norm = np.linalg.norm(starting_point,'nuc')\n",
    "\n",
    "        norms = []\n",
    "        distances = []\n",
    "        sing_vals = []\n",
    "\n",
    "        current_point = starting_point\n",
    "\n",
    "        #pl.imshow(np.abs((current_point-original)/original), cmap=plt.get_cmap('hot'),\n",
    "        #          interpolation='nearest', vmin=0, vmax=1)\n",
    "        #pl.colorbar()\n",
    "\n",
    "\n",
    "        initial_s = 4\n",
    "        s = 4\n",
    "        portion = 1.1\n",
    "        for i in range(max_steps):\n",
    "            cur_norm = np.linalg.norm(current_point,'nuc')\n",
    "            norms.append(cur_norm)\n",
    "            sing_vals.append(np.linalg.svd(current_point, compute_uv=False))\n",
    "            distances.append(np.linalg.norm(current_point-original,'fro'))\n",
    "            diff = cur_norm - prev_norm\n",
    "\n",
    "            # portion really should depend on s since smaller s implies the need of a more accurate gradient estimate\n",
    "            #portion = 1 - np.exp(-1/(20*s))\n",
    "            #if i % 1000 == 0:\n",
    "            #print(i, cur_norm, diff, np.linalg.norm(current_point-original,'fro'), initial_s, s, portion)\n",
    "            prev_norm = cur_norm\n",
    "            \n",
    "            if np.linalg.norm(current_point-original,'fro') < threshold:\n",
    "                return knowns\n",
    "            \n",
    "            if diff >= 0 and i > 1:\n",
    "                break\n",
    "\n",
    "            ### slowest part of the code ###\n",
    "            descent = np.linalg.lstsq(np.diag(comp_hessian(current_point,boolMask,obj_func)),\n",
    "               comp_grad(current_point,boolMask,obj_func), rcond=None)[0]\n",
    "\n",
    "            descent_matrix = np.zeros([n,n])\n",
    "            count = 0\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if boolMask[i,j]:\n",
    "                        descent_matrix[i,j] = descent[count]\n",
    "                        count = count + 1\n",
    "\n",
    "            reg = 0.39\n",
    "            next_point = current_point - reg*descent_matrix\n",
    "\n",
    "            current_point = next_point\n",
    "\n",
    "        # Next try gradient descent:\n",
    "        \n",
    "        def comp_grad(m,boolMask):\n",
    "            \"\"\" Computes gradient that maximizes the objective function \"\"\"\n",
    "            epsilon = 1e-3\n",
    "\n",
    "            grad = np.zeros([n,n])\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if boolMask[i,j]:\n",
    "                        diff = np.zeros([n,n])\n",
    "                        diff[i,j] = epsilon\n",
    "                        grad[i,j] = (obj_func(m + diff) - obj_func(m - diff))/(2*epsilon)\n",
    "\n",
    "            return grad\n",
    "        \n",
    "        def line_search(point, grad, obj_func, s = 4, threshold = 1e-10):\n",
    "            \"\"\" Finds a maximum step size that maximizes the descent (since computing gradient is hard) \"\"\"\n",
    "\n",
    "            choice = point - grad * s\n",
    "            while obj_func(choice) > obj_func(point):\n",
    "                s = s / 2\n",
    "                choice = point - grad * s\n",
    "\n",
    "            initial_s = s\n",
    "\n",
    "            while True:\n",
    "                left = choice + grad * s/2\n",
    "                right = point - grad * s/2\n",
    "\n",
    "                s = s / 2\n",
    "                if obj_func(left) < obj_func(right):\n",
    "                    choice = left\n",
    "                else:\n",
    "                    choice = right\n",
    "\n",
    "                if np.abs(obj_func(left) - obj_func(right)) < threshold:\n",
    "                    break\n",
    "\n",
    "            return (choice, initial_s, s)\n",
    "\n",
    "        starting_point = np.copy(original)\n",
    "\n",
    "        boolMask = np.ma.make_mask(np.where(np.array(mask) < 0.5, 1, 0))\n",
    "        starting_point[boolMask] = 0\n",
    "\n",
    "        prev_norm = np.linalg.norm(starting_point,'nuc')\n",
    "\n",
    "        norms = []\n",
    "        distances = []\n",
    "        sing_vals = []\n",
    "\n",
    "        current_point = starting_point\n",
    "\n",
    "        initial_s = 4\n",
    "        s = 4\n",
    "        portion = 1.1\n",
    "        for i in range(threshold):\n",
    "            cur_norm = np.linalg.norm(current_point,'nuc')\n",
    "            norms.append(cur_norm)\n",
    "            sing_vals.append(np.linalg.svd(current_point, compute_uv=False))\n",
    "            distances.append(np.linalg.norm(current_point-original,'fro'))\n",
    "            diff = cur_norm - prev_norm\n",
    "\n",
    "            #print(i, cur_norm, diff, np.linalg.norm(current_point-original,'fro'))\n",
    "            prev_norm = cur_norm\n",
    "            \n",
    "            if np.linalg.norm(current_point-original,'fro') < threshold:\n",
    "                return knowns\n",
    "            \n",
    "            if diff >= 0 and i > 1:\n",
    "                break\n",
    "\n",
    "            ### slowest part of the code ###\n",
    "            grad = comp_grad(current_point,boolMask)\n",
    "            current_point, initial_s, s = line_search(current_point, grad, obj_func, s = initial_s)\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 21\n",
      "6 29\n",
      "7 44\n",
      "8 49\n",
      "9 71\n",
      "10 97\n",
      "11 101\n",
      "12 142\n",
      "13 122\n",
      "14 194\n",
      "15 166\n",
      "16 185\n",
      "17 198\n",
      "18 255\n",
      "19 257\n",
      "20 273\n",
      "21 316\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b3402e5f7c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmin_knowns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_min_knowns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin_knowns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mn_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-ba43732e78a2>\u001b[0m in \u001b[0;36mget_min_knowns\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m### slowest part of the code ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             descent = np.linalg.lstsq(np.diag(comp_hessian(current_point,boolMask,obj_func)),\n\u001b[0;32m--> 105\u001b[0;31m                comp_grad(current_point,boolMask,obj_func), rcond=None)[0]\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mdescent_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DDd->Ddid'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'ddd->ddid'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_lstsq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \u001b[0;31m# remove the axis we added\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_vals = []\n",
    "min_knowns_vals = []\n",
    "\n",
    "for n in range(4,10000):\n",
    "    min_knowns = get_min_knowns(n)\n",
    "    if min_knowns:\n",
    "        n_vals.append(n)\n",
    "        min_knowns_vals.append(min_knowns)\n",
    "        print(n, min_knowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe40befe320>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_vals, min_knowns_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('convergence_nuc_norm_n_vals', n_vals)\n",
    "np.save('convergence_nuc_norm_min_known_vals', min_knowns_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
