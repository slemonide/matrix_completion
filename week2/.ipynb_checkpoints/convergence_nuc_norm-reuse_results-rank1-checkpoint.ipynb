{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_func(m):\n",
    "    svd = np.linalg.svd(m, compute_uv=False)\n",
    "\n",
    "    return np.sum(svd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_min_knowns(n,prev_knowns=1):\n",
    "    \n",
    "    rank = 2\n",
    "\n",
    "    U = np.random.randn(n, rank)\n",
    "    V = np.random.randn(n, rank)\n",
    "    original = np.dot(U, V.T)\n",
    "\n",
    "    for knowns in range(np.max([prev_knowns - 20, 1]), n*n):\n",
    "    #for knowns in range(prev_knowns, n*n):\n",
    "        max_steps = 100000\n",
    "        threshold = 1 # distance between solution and answer when they are considered the same\n",
    "\n",
    "        unknowns = n*n - knowns\n",
    "\n",
    "        #print('>',n*n, unknowns)\n",
    "        \n",
    "        mask = np.array([0] * unknowns + [1] * (n*n - unknowns))\n",
    "        np.random.shuffle(mask)\n",
    "        mask = np.reshape(mask, [n,n])\n",
    "        mask = np.ma.make_mask(mask)\n",
    "\n",
    "\n",
    "        \n",
    "        # First try Newton's method:\n",
    "\n",
    "        def comp_grad(m, boolMask, obj_func):\n",
    "            \"\"\" Computes gradient that maximizes the objective function \"\"\"\n",
    "            epsilon = 1e-3\n",
    "\n",
    "            # Yes, grad is a vector now\n",
    "            grad = []\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if boolMask[i,j] and np.random.random() > 1 - portion:\n",
    "                        diff = np.zeros([n,n])\n",
    "                        diff[i,j] = epsilon\n",
    "                        grad.append((obj_func(m + diff) - obj_func(m - diff))/(2*epsilon))\n",
    "\n",
    "            return grad\n",
    "\n",
    "        def comp_hessian(m, boolMask, of):\n",
    "            \"\"\" Computes hessian (only diagonal) \"\"\"\n",
    "            epsilon = 1e-3\n",
    "\n",
    "            hessian = []\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if boolMask[i,j]:\n",
    "                        row = []\n",
    "\n",
    "                        diff = np.zeros([n,n])\n",
    "                        diff[i,j] = epsilon\n",
    "                        hessian.append((of(m + diff) + of(m - diff) - 2*of(m))/epsilon**2)\n",
    "\n",
    "            return hessian\n",
    "\n",
    "\n",
    "        starting_point = np.copy(original)\n",
    "\n",
    "        boolMask = np.ma.make_mask(np.where(np.array(mask) < 0.5, 1, 0))\n",
    "        starting_point[boolMask] = 0\n",
    "\n",
    "        prev_norm = np.linalg.norm(starting_point,'nuc')\n",
    "\n",
    "        norms = []\n",
    "        distances = []\n",
    "        sing_vals = []\n",
    "\n",
    "        current_point = starting_point\n",
    "\n",
    "        #pl.imshow(np.abs((current_point-original)/original), cmap=plt.get_cmap('hot'),\n",
    "        #          interpolation='nearest', vmin=0, vmax=1)\n",
    "        #pl.colorbar()\n",
    "\n",
    "\n",
    "        initial_s = 4\n",
    "        s = 4\n",
    "        portion = 1.1\n",
    "        for i in range(max_steps):\n",
    "            cur_norm = np.linalg.norm(current_point,'nuc')\n",
    "            norms.append(cur_norm)\n",
    "            sing_vals.append(np.linalg.svd(current_point, compute_uv=False))\n",
    "            distances.append(np.linalg.norm(current_point-original,'fro'))\n",
    "            diff = cur_norm - prev_norm\n",
    "\n",
    "            # portion really should depend on s since smaller s implies the need of a more accurate gradient estimate\n",
    "            #portion = 1 - np.exp(-1/(20*s))\n",
    "            #if i % 1000 == 0:\n",
    "            #print(i, cur_norm, diff, np.linalg.norm(current_point-original,'fro'), initial_s, s, portion)\n",
    "            prev_norm = cur_norm\n",
    "            \n",
    "            if np.linalg.norm(current_point-original,'fro') < threshold:\n",
    "                return knowns\n",
    "            \n",
    "            if diff >= 0 and i > 1:\n",
    "                break\n",
    "\n",
    "            ### slowest part of the code ###\n",
    "            descent = np.linalg.lstsq(np.diag(comp_hessian(current_point,boolMask,obj_func)),\n",
    "               comp_grad(current_point,boolMask,obj_func), rcond=None)[0]\n",
    "\n",
    "            descent_matrix = np.zeros([n,n])\n",
    "            count = 0\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if boolMask[i,j]:\n",
    "                        descent_matrix[i,j] = descent[count]\n",
    "                        count = count + 1\n",
    "\n",
    "            reg = 0.39\n",
    "            next_point = current_point - reg*descent_matrix\n",
    "\n",
    "            current_point = next_point\n",
    "\n",
    "        # Next try gradient descent:\n",
    "        \n",
    "        def comp_grad(m,boolMask):\n",
    "            \"\"\" Computes gradient that maximizes the objective function \"\"\"\n",
    "            epsilon = 1e-3\n",
    "\n",
    "            grad = np.zeros([n,n])\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    if boolMask[i,j]:\n",
    "                        diff = np.zeros([n,n])\n",
    "                        diff[i,j] = epsilon\n",
    "                        grad[i,j] = (obj_func(m + diff) - obj_func(m - diff))/(2*epsilon)\n",
    "\n",
    "            return grad\n",
    "        \n",
    "        def line_search(point, grad, obj_func, s = 4, threshold = 1e-10):\n",
    "            \"\"\" Finds a maximum step size that maximizes the descent (since computing gradient is hard) \"\"\"\n",
    "\n",
    "            choice = point - grad * s\n",
    "            while obj_func(choice) > obj_func(point):\n",
    "                s = s / 2\n",
    "                choice = point - grad * s\n",
    "\n",
    "            initial_s = s\n",
    "\n",
    "            while True:\n",
    "                left = choice + grad * s/2\n",
    "                right = point - grad * s/2\n",
    "\n",
    "                s = s / 2\n",
    "                if obj_func(left) < obj_func(right):\n",
    "                    choice = left\n",
    "                else:\n",
    "                    choice = right\n",
    "\n",
    "                if np.abs(obj_func(left) - obj_func(right)) < threshold:\n",
    "                    break\n",
    "\n",
    "            return (choice, initial_s, s)\n",
    "\n",
    "        starting_point = np.copy(original)\n",
    "\n",
    "        boolMask = np.ma.make_mask(np.where(np.array(mask) < 0.5, 1, 0))\n",
    "        starting_point[boolMask] = 0\n",
    "\n",
    "        prev_norm = np.linalg.norm(starting_point,'nuc')\n",
    "\n",
    "        norms = []\n",
    "        distances = []\n",
    "        sing_vals = []\n",
    "\n",
    "        current_point = starting_point\n",
    "\n",
    "        initial_s = 4\n",
    "        s = 4\n",
    "        portion = 1.1\n",
    "        for i in range(threshold):\n",
    "            cur_norm = np.linalg.norm(current_point,'nuc')\n",
    "            norms.append(cur_norm)\n",
    "            sing_vals.append(np.linalg.svd(current_point, compute_uv=False))\n",
    "            distances.append(np.linalg.norm(current_point-original,'fro'))\n",
    "            diff = cur_norm - prev_norm\n",
    "\n",
    "            #print(i, cur_norm, diff, np.linalg.norm(current_point-original,'fro'))\n",
    "            prev_norm = cur_norm\n",
    "            \n",
    "            if np.linalg.norm(current_point-original,'fro') < threshold:\n",
    "                return knowns\n",
    "            \n",
    "            if diff >= 0 and i > 1:\n",
    "                break\n",
    "\n",
    "            ### slowest part of the code ###\n",
    "            grad = comp_grad(current_point,boolMask)\n",
    "            current_point, initial_s, s = line_search(current_point, grad, obj_func, s = initial_s)\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_min_knowns(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 14\n",
      "5 21\n",
      "6 25\n",
      "7 40\n",
      "8 60\n",
      "9 61\n",
      "10 79\n",
      "11 91\n",
      "12 110\n",
      "13 166\n",
      "14 162\n",
      "15 190\n",
      "16 255\n",
      "17 286\n",
      "18 275\n",
      "19 266\n",
      "20 259\n",
      "21 273\n",
      "22 325\n",
      "23 352\n",
      "24 351\n",
      "25 391\n",
      "26 380\n",
      "27 449\n",
      "28 448\n",
      "29 515\n",
      "30 499\n",
      "31 554\n",
      "32 534\n",
      "33 572\n"
     ]
    }
   ],
   "source": [
    "n_vals = []\n",
    "min_knowns_vals = []\n",
    "\n",
    "prev = 1\n",
    "for n in range(4,10000):\n",
    "    min_knowns = get_min_knowns(n, prev)\n",
    "    if min_knowns:\n",
    "        prev = min_knowns\n",
    "        n_vals.append(n)\n",
    "        min_knowns_vals.append(min_knowns)\n",
    "        print(n, min_knowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
